{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c063bf7",
   "metadata": {},
   "source": [
    "# Backpropagation: It is an algo for supervised learning of ANN ,given an ANN and error function it calculates the gradient of error function with respect to its loss\n",
    "    gradient reffer to the derivation of the loss function with respect to thier weigths or biasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b68d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5269dc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>LPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  LPA\n",
       "0     8              8    4\n",
       "1     7              9    5\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]],columns=[\"cgpa\",\"profile_score\",\"LPA\"])\n",
    "df  # data set created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3b63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d8efa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential() # to create architecture\n",
    "model.add(Dense(2,activation=\"linear\",input_dim=2))# adding first layer\n",
    "model.add(Dense(1,activation=\"linear\")) # adding second layer\n",
    "model.summary() # to see are architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be83efaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.6184245, -1.1607895],\n",
       "        [ 1.0857238,  0.3754053]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[ 1.0517253],\n",
       "        [-0.9165685]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() # keras initialize with random weights and biasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7ef6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers=keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31031ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  8],\n",
       "       [ 7,  9],\n",
       "       [ 6, 10],\n",
       "       [ 5, 12]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0c6396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "4/4 [==============================] - 0s 724us/step - loss: 24.2128\n",
      "Epoch 2/75\n",
      "4/4 [==============================] - 0s 712us/step - loss: 22.5489\n",
      "Epoch 3/75\n",
      "4/4 [==============================] - 0s 594us/step - loss: 20.9521\n",
      "Epoch 4/75\n",
      "4/4 [==============================] - 0s 637us/step - loss: 19.4257\n",
      "Epoch 5/75\n",
      "4/4 [==============================] - 0s 683us/step - loss: 17.9814\n",
      "Epoch 6/75\n",
      "4/4 [==============================] - 0s 525us/step - loss: 16.6298\n",
      "Epoch 7/75\n",
      "4/4 [==============================] - 0s 558us/step - loss: 15.3053\n",
      "Epoch 8/75\n",
      "4/4 [==============================] - 0s 623us/step - loss: 14.1558\n",
      "Epoch 9/75\n",
      "4/4 [==============================] - 0s 538us/step - loss: 12.9955\n",
      "Epoch 10/75\n",
      "4/4 [==============================] - 0s 564us/step - loss: 11.9957\n",
      "Epoch 11/75\n",
      "4/4 [==============================] - 0s 624us/step - loss: 11.0098\n",
      "Epoch 12/75\n",
      "4/4 [==============================] - 0s 495us/step - loss: 10.1392\n",
      "Epoch 13/75\n",
      "4/4 [==============================] - 0s 525us/step - loss: 9.2462\n",
      "Epoch 14/75\n",
      "4/4 [==============================] - 0s 506us/step - loss: 8.4993\n",
      "Epoch 15/75\n",
      "4/4 [==============================] - 0s 507us/step - loss: 7.8114\n",
      "Epoch 16/75\n",
      "4/4 [==============================] - 0s 560us/step - loss: 7.1031\n",
      "Epoch 17/75\n",
      "4/4 [==============================] - 0s 521us/step - loss: 6.5139\n",
      "Epoch 18/75\n",
      "4/4 [==============================] - 0s 598us/step - loss: 5.9791\n",
      "Epoch 19/75\n",
      "4/4 [==============================] - 0s 642us/step - loss: 5.4391\n",
      "Epoch 20/75\n",
      "4/4 [==============================] - 0s 507us/step - loss: 4.9868\n",
      "Epoch 21/75\n",
      "4/4 [==============================] - 0s 545us/step - loss: 4.5581\n",
      "Epoch 22/75\n",
      "4/4 [==============================] - 0s 620us/step - loss: 4.1460\n",
      "Epoch 23/75\n",
      "4/4 [==============================] - 0s 513us/step - loss: 3.7723\n",
      "Epoch 24/75\n",
      "4/4 [==============================] - 0s 630us/step - loss: 3.4576\n",
      "Epoch 25/75\n",
      "4/4 [==============================] - 0s 511us/step - loss: 3.1469\n",
      "Epoch 26/75\n",
      "4/4 [==============================] - 0s 527us/step - loss: 2.8833\n",
      "Epoch 27/75\n",
      "4/4 [==============================] - 0s 650us/step - loss: 2.6079\n",
      "Epoch 28/75\n",
      "4/4 [==============================] - 0s 524us/step - loss: 2.4036\n",
      "Epoch 29/75\n",
      "4/4 [==============================] - 0s 688us/step - loss: 2.2064\n",
      "Epoch 30/75\n",
      "4/4 [==============================] - 0s 533us/step - loss: 1.9864\n",
      "Epoch 31/75\n",
      "4/4 [==============================] - 0s 506us/step - loss: 1.8278\n",
      "Epoch 32/75\n",
      "4/4 [==============================] - 0s 440us/step - loss: 1.6579\n",
      "Epoch 33/75\n",
      "4/4 [==============================] - 0s 545us/step - loss: 1.5424\n",
      "Epoch 34/75\n",
      "4/4 [==============================] - 0s 758us/step - loss: 1.4141\n",
      "Epoch 35/75\n",
      "4/4 [==============================] - 0s 526us/step - loss: 1.2919\n",
      "Epoch 36/75\n",
      "4/4 [==============================] - 0s 469us/step - loss: 1.1686\n",
      "Epoch 37/75\n",
      "4/4 [==============================] - 0s 608us/step - loss: 1.0797\n",
      "Epoch 38/75\n",
      "4/4 [==============================] - 0s 499us/step - loss: 1.0159\n",
      "Epoch 39/75\n",
      "4/4 [==============================] - 0s 600us/step - loss: 0.9233\n",
      "Epoch 40/75\n",
      "4/4 [==============================] - 0s 693us/step - loss: 0.8514\n",
      "Epoch 41/75\n",
      "4/4 [==============================] - 0s 569us/step - loss: 0.7935\n",
      "Epoch 42/75\n",
      "4/4 [==============================] - 0s 533us/step - loss: 0.7492\n",
      "Epoch 43/75\n",
      "4/4 [==============================] - 0s 519us/step - loss: 0.7023\n",
      "Epoch 44/75\n",
      "4/4 [==============================] - 0s 531us/step - loss: 0.6595\n",
      "Epoch 45/75\n",
      "4/4 [==============================] - 0s 547us/step - loss: 0.6091\n",
      "Epoch 46/75\n",
      "4/4 [==============================] - 0s 777us/step - loss: 0.5744\n",
      "Epoch 47/75\n",
      "4/4 [==============================] - 0s 569us/step - loss: 0.5436\n",
      "Epoch 48/75\n",
      "4/4 [==============================] - 0s 485us/step - loss: 0.5229\n",
      "Epoch 49/75\n",
      "4/4 [==============================] - 0s 524us/step - loss: 0.4859\n",
      "Epoch 50/75\n",
      "4/4 [==============================] - 0s 525us/step - loss: 0.4745\n",
      "Epoch 51/75\n",
      "4/4 [==============================] - 0s 623us/step - loss: 0.4523\n",
      "Epoch 52/75\n",
      "4/4 [==============================] - 0s 537us/step - loss: 0.4250\n",
      "Epoch 53/75\n",
      "4/4 [==============================] - 0s 675us/step - loss: 0.4112\n",
      "Epoch 54/75\n",
      "4/4 [==============================] - 0s 619us/step - loss: 0.4003\n",
      "Epoch 55/75\n",
      "4/4 [==============================] - 0s 491us/step - loss: 0.3845\n",
      "Epoch 56/75\n",
      "4/4 [==============================] - 0s 474us/step - loss: 0.3741\n",
      "Epoch 57/75\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.3675\n",
      "Epoch 58/75\n",
      "4/4 [==============================] - 0s 511us/step - loss: 0.3530\n",
      "Epoch 59/75\n",
      "4/4 [==============================] - 0s 525us/step - loss: 0.3461\n",
      "Epoch 60/75\n",
      "4/4 [==============================] - 0s 632us/step - loss: 0.3404\n",
      "Epoch 61/75\n",
      "4/4 [==============================] - 0s 516us/step - loss: 0.3352\n",
      "Epoch 62/75\n",
      "4/4 [==============================] - 0s 486us/step - loss: 0.3286\n",
      "Epoch 63/75\n",
      "4/4 [==============================] - 0s 491us/step - loss: 0.3221\n",
      "Epoch 64/75\n",
      "4/4 [==============================] - 0s 634us/step - loss: 0.3160\n",
      "Epoch 65/75\n",
      "4/4 [==============================] - 0s 480us/step - loss: 0.3089\n",
      "Epoch 66/75\n",
      "4/4 [==============================] - 0s 486us/step - loss: 0.3036\n",
      "Epoch 67/75\n",
      "4/4 [==============================] - 0s 522us/step - loss: 0.3001\n",
      "Epoch 68/75\n",
      "4/4 [==============================] - 0s 513us/step - loss: 0.2960\n",
      "Epoch 69/75\n",
      "4/4 [==============================] - 0s 526us/step - loss: 0.2943\n",
      "Epoch 70/75\n",
      "4/4 [==============================] - 0s 495us/step - loss: 0.2894\n",
      "Epoch 71/75\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.2868\n",
      "Epoch 72/75\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2827\n",
      "Epoch 73/75\n",
      "4/4 [==============================] - 0s 524us/step - loss: 0.2806\n",
      "Epoch 74/75\n",
      "4/4 [==============================] - 0s 523us/step - loss: 0.2794\n",
      "Epoch 75/75\n",
      "4/4 [==============================] - 0s 470us/step - loss: 0.2739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x152eb32e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df.iloc[:,0:-1].values,df[\"LPA\"].values,epochs=75,verbose=1,batch_size=1) # in every epoch calculation will be made for every row \n",
    "# so in one epoch there are 4/4 which mean every row is calculated in each of the epoch\n",
    "# we used .values because keras accept values in array format rather than datframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8be5f1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.74420863, -1.0353068 ],\n",
       "        [ 0.9665745 ,  0.494361  ]], dtype=float32),\n",
       " array([-0.12395521,  0.12370627], dtype=float32),\n",
       " array([[ 0.9552806 ],\n",
       "        [-0.80749464]], dtype=float32),\n",
       " array([-0.12759478], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() # these are the otimal value of weights which we got using keras were are loss is at minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c4410fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we did backpropagation for classification problem above , backpropagation takes place in every epoch for all the number of rows behind the scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f237c",
   "metadata": {},
   "source": [
    "# for classification problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb9725a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPA</th>\n",
       "      <th>Profile_score</th>\n",
       "      <th>Placement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPA  Profile_score  Placement\n",
       "0    8              8          1\n",
       "1    7              9          1\n",
       "2    6             10          0\n",
       "3    5              5          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a classification data\n",
    "data={\n",
    "    \"CPA\":[8,7,6,5],\n",
    "    \"Profile_score\":[8,9,10,5],\n",
    "    \"Placement\":[1,1,0,0]\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9349e356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Dense(2,activation=\"sigmoid\",input_dim=2))# adding first layer\n",
    "model1.add(Dense(1,activation=\"sigmoid\")) # adding second layer\n",
    "model1.summary() # to see are architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc4f7dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03803265, -0.56172645],\n",
       "        [ 0.3731904 , -0.8081049 ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.45265305],\n",
       "        [1.0102154 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dfaab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1=keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "model1.compile(loss=\"binary_crossentropy\",optimizer=optimizer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05baad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 651us/step - loss: 0.7130\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 685us/step - loss: 0.7118\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 614us/step - loss: 0.7116\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 641us/step - loss: 0.7117\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 619us/step - loss: 0.7111\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 632us/step - loss: 0.7111\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 781us/step - loss: 0.7107\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 596us/step - loss: 0.7108\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 572us/step - loss: 0.7103\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 603us/step - loss: 0.7100\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 605us/step - loss: 0.7100\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 634us/step - loss: 0.7096\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 670us/step - loss: 0.7095\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 586us/step - loss: 0.7092\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 562us/step - loss: 0.7094\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 556us/step - loss: 0.7089\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 609us/step - loss: 0.7086\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 888us/step - loss: 0.7087\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 504us/step - loss: 0.7084\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 610us/step - loss: 0.7082\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 570us/step - loss: 0.7082\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 531us/step - loss: 0.7076\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 560us/step - loss: 0.7076\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 693us/step - loss: 0.7076\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 550us/step - loss: 0.7072\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 476us/step - loss: 0.7069\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 512us/step - loss: 0.7068\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 497us/step - loss: 0.7067\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 590us/step - loss: 0.7068\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 665us/step - loss: 0.7063\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 486us/step - loss: 0.7061\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 536us/step - loss: 0.7059\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 607us/step - loss: 0.7059\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 496us/step - loss: 0.7060\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 546us/step - loss: 0.7057\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 560us/step - loss: 0.7052\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 525us/step - loss: 0.7051\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.7049\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 542us/step - loss: 0.7048\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 469us/step - loss: 0.7051\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 654us/step - loss: 0.7045\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 641us/step - loss: 0.7043\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 469us/step - loss: 0.7044\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 471us/step - loss: 0.7044\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 601us/step - loss: 0.7039\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 528us/step - loss: 0.7038\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 607us/step - loss: 0.7040\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 566us/step - loss: 0.7038\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 856us/step - loss: 0.7033\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 530us/step - loss: 0.7032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15415f3a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(df.iloc[:,:-1].values,df[\"Placement\"].values,epochs=50,verbose=1,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e36f8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was the method to train any nueral network in deep learning\n",
    "# somehow in above case our loss was not reducing much reason could be anything but the main idea was to show how we work with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad187895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
